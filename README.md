# Система детекции средств индивидуальной защиты (СИЗ)

Проект для обучения модели YOLOv8 на детекцию средств индивидуальной защиты:
- **Защитная каска** (оранжевая или белая) - класс 0
- **Сигнальный жилет** - класс 1

**Оптимизировано для:**
- Высокого угла обзора камер (сверху вниз)
- Очень маленьких объектов (люди на большом расстоянии)
- Быстрого движения объектов

## Быстрый старт

### 1. Установка зависимостей

```bash
pip install -r requirements.txt
```

### 2. Подготовка данных

Поместите разметенные изображения в структуру:
```
data/
├── images/
│   ├── train/          # Изображения для обучения
│   └── val/            # Изображения для валидации
└── labels/
    ├── train/          # Файлы разметки (.txt) для обучения
    └── val/            # Файлы разметки (.txt) для валидации
```

### 3. Запуск полного цикла обучения

```bash
python run_full_pipeline.py
```

Этот скрипт автоматически:
- Создаст структуру проекта и конфигурацию
- Извлечет кадры из видео (если есть в папке `videos/`)
- Сделает автоматическую предразметку
- Разделит датасет на train/val
- Проверит структуру данных
- Обучит модель YOLOv8
- Выполнит быстрый тест модели

## Подробная инструкция по разметке данных

### Что нужно размечать

#### 1. Защитная каска (helmet) - класс 0
- **Цвет: оранжевый** (основной цвет для детекции)
- Разные типы защитных касок
- Разные углы обзора (спереди, сбоку, сверху)
- Разные условия освещения
- Каски могут быть частично видны

#### 2. Сигнальный жилет (vest) - класс 1
- Светоотражающие жилеты
- Обычные сигнальные жилеты
- Разные позы людей (стоя, сидя, в движении)
- Частично видимые жилеты
- Жилеты разных цветов (желтый, оранжевый, зеленый)

### Рекомендации по сбору данных

- **Минимум 100-200 изображений на класс** для базового обучения
- **Желательно 500+ изображений на класс** для качественной модели
- Разнообразие условий:
  - Разное освещение (дневное, искусственное, темное)
  - Разные ракурсы и углы обзора
  - Разные расстояния до объектов
  - Разные фоны (производство, стройка, улица)
  - Разные погодные условия (если съемка на улице)
- Изображения должны быть в формате **JPG** или **PNG**
- Рекомендуемое разрешение: **640x640** или выше

### Как правильно размечать файлы

#### Формат разметки YOLO

Каждое изображение должно иметь соответствующий текстовый файл с разметкой в формате YOLO.

**Формат файла разметки (.txt):**
```
class_id center_x center_y width height
```

Где:
- `class_id` - номер класса:
  - `0` для защитной каски (helmet)
  - `1` для сигнального жилета (vest)
- `center_x` - координата X центра объекта (нормализованная от 0 до 1)
- `center_y` - координата Y центра объекта (нормализованная от 0 до 1)
- `width` - ширина bounding box (нормализованная от 0 до 1)
- `height` - высота bounding box (нормализованная от 0 до 1)

**Пример файла разметки (image001.txt):**
```
0 0.5 0.3 0.2 0.25
1 0.7 0.6 0.15 0.2
```

Это означает:
- Каска (класс 0) в центре изображения
- Жилет (класс 1) справа внизу

#### Правила разметки

1. **Bounding box должен плотно обхватывать объект:**
   - Не оставляйте больших зазоров
   - Не обрезайте части объекта
   - Включайте небольшие отступы (2-5 пикселей)

2. **Для каски:**
   - Размечайте всю видимую часть каски
   - Если каска частично скрыта, размечайте только видимую часть
   - Включайте козырек, если он виден

3. **Для жилета:**
   - Размечайте весь видимый жилет
   - Если жилет частично скрыт, размечайте только видимую часть
   - Включайте светоотражающие полосы

4. **Имена файлов:**
   - Изображение: `image001.jpg`
   - Разметка: `image001.txt` (то же имя, расширение .txt)

#### Инструменты для разметки

**1. LabelImg (рекомендуется)**
- Установка: `pip install labelImg`
- Запуск: `labelImg`
- **ВАЖНО:** При сохранении выберите формат **YOLO** (не PascalVOC!)
- Настройка классов:
  - Откройте `data/predefined_classes.txt` (создайте файл)
  - Добавьте строки:
    ```
    helmet
    vest
    ```

**2. Roboflow (онлайн)**
- https://roboflow.com/
- Бесплатный аккаунт
- Удобный интерфейс
- Экспорт в формате YOLO

**3. CVAT**
- https://github.com/openvinotoolkit/cvat
- Для больших команд
- Поддержка формата YOLO

### Структура директорий

После разметки разместите файлы так:

```
data/
├── images/
│   ├── train/          # 80-90% изображений для обучения
│   │   ├── image001.jpg
│   │   ├── image002.jpg
│   │   └── ...
│   └── val/            # 10-20% изображений для валидации
│       ├── image101.jpg
│       ├── image102.jpg
│       └── ...
└── labels/
    ├── train/          # Разметка для обучения
    │   ├── image001.txt
    │   ├── image002.txt
    │   └── ...
    └── val/            # Разметка для валидации
        ├── image101.txt
        ├── image102.txt
        └── ...
```

### Автоматическое разделение на train/val

Разделение выполняется автоматически в `run_full_pipeline.py`. Если нужно разделить вручную, используйте ноутбук `notebooks/data_preparation.ipynb` или импортируйте функцию:

```python
from src.data.split_dataset import split_dataset
split_dataset(
    train_images_dir="data/images/train",
    train_labels_dir="data/labels/train",
    val_ratio=0.2
)
```

## Обучение модели

### Полный цикл обучения (рекомендуется)

```bash
python run_full_pipeline.py
```

### Ручной запуск через ноутбук

1. Откройте Jupyter: `jupyter lab`
2. Запустите ноутбук `notebooks/training.ipynb`
3. Модель будет обучена и сохранена в `models/ppe_detection/weights/best.pt`

### Ручной запуск через Python

```python
from src.models.train_model import PPEDetectorTrainer

trainer = PPEDetectorTrainer()
results = trainer.train(epochs=30, batch_size=16)
```

Модель будет обучена и сохранена в `models/ppe_detection/weights/best.pt`

### Параметры обучения

- Эпохи: 30
- Размер изображения: 640x640
- Устройство: CPU (автоматически переключится на GPU, если доступен)
- Размер батча: 16
- Ранняя остановка: после 10 эпох без улучшения

## Использование обученной модели

После обучения модель можно использовать для детекции:

### Через ноутбук (рекомендуется)

1. Откройте `notebooks/inference.ipynb`
2. Загрузите модель и протестируйте на изображениях/видео/камере

### Через Python

```python
from src.inference.detect_utils import PPEDetector

# Детекция на изображении
detector = PPEDetector("models/ppe_detection/weights/best.pt")
result_img, detections = detector.detect_image("test.jpg", save_result=True)

# Детекция на видео
detector.detect_video("input.mp4", output_path="output/detected.mp4")

# Детекция с камеры
detector.detect_camera(camera_id=0)
```

## Требования

- Python 3.8+
- ultralytics (YOLOv8)
- opencv-python
- numpy
- torch

## Структура проекта

```
hahaton123/
├── config/
│   └── ppe_data.yaml          # Конфигурация датасета
├── data/
│   ├── images/
│   │   ├── train/
│   │   └── val/
│   └── labels/
│       ├── train/
│       └── val/
├── models/
│   └── ppe_detection/          # Обученные модели
├── output/                     # Результаты детекции
├── notebooks/                   # Jupyter ноутбуки
│   ├── data_preparation.ipynb  # Подготовка данных
│   ├── training.ipynb          # Обучение модели
│   ├── inference.ipynb         # Инференс
│   └── project_structure.ipynb # Структура проекта
├── src/                        # Исходный код
│   ├── data/                   # Модули для работы с данными
│   ├── models/                 # Модули для обучения
│   ├── inference/              # Модули для инференса
│   └── utils/                  # Утилиты
├── run_full_pipeline.py        # Полный автоматический пайплайн
├── requirements.txt            # Зависимости
├── README.md                   # Документация
└── ANNOTATION_GUIDE.md         # Руководство по разметке

```
